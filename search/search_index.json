{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the DANDI archive documentation The Web interface to the DANDI archive is located at https://dandiarchive.org . This site provides information on how to interact with the archive. Where to communicate: For general discussion post on https://neurostars.org and use the tag dandi . Report DANDI related bugs here . Register on DANDI using Github and we will invite you to the DANDI Slack workspace. Make sure to use the Register with OAuth option. See here for details on how to register . Email us: info@dandiarchive.org How to use this documentation To start using the archive head over to: Working with DANDI If you want to know more about the DANDI project, its goals and the problems it tries to solve: check out our introduction . The DANDI archive stores cellular neurophysiology datasets using NWB, BIDS, and other BRAIN Initiative standards. If you are unfamiliar with such things, head over to our FAQ . You do not need an in depth understanding of what those things are to use the DANDI archive but some \"big picture\" conceptual understanding could save you from a lot of confusion. \ud83d\ude09 Not sure how the project is organized? Check out the project structure page. Licence This work is licensed under a Creative Commons Attribution 4.0 International License . Contributing and feedback We are looking for people to give us feedback on this documentation if anything is unclear by opening an issue on our repository . You can also get in touch on our Slack channel. You will be invited once you [register an account] on the archive. If you want to get started right away and contribute directly to this documentation, you can find references and how-to in the about section .","title":"Welcome"},{"location":"#welcome-to-the-dandi-archive-documentation","text":"The Web interface to the DANDI archive is located at https://dandiarchive.org . This site provides information on how to interact with the archive.","title":"Welcome to the DANDI archive documentation"},{"location":"#where-to-communicate","text":"For general discussion post on https://neurostars.org and use the tag dandi . Report DANDI related bugs here . Register on DANDI using Github and we will invite you to the DANDI Slack workspace. Make sure to use the Register with OAuth option. See here for details on how to register . Email us: info@dandiarchive.org","title":"Where to communicate:"},{"location":"#how-to-use-this-documentation","text":"To start using the archive head over to: Working with DANDI If you want to know more about the DANDI project, its goals and the problems it tries to solve: check out our introduction . The DANDI archive stores cellular neurophysiology datasets using NWB, BIDS, and other BRAIN Initiative standards. If you are unfamiliar with such things, head over to our FAQ . You do not need an in depth understanding of what those things are to use the DANDI archive but some \"big picture\" conceptual understanding could save you from a lot of confusion. \ud83d\ude09 Not sure how the project is organized? Check out the project structure page.","title":"How to use this documentation"},{"location":"#licence","text":"This work is licensed under a Creative Commons Attribution 4.0 International License .","title":"Licence"},{"location":"#contributing-and-feedback","text":"We are looking for people to give us feedback on this documentation if anything is unclear by opening an issue on our repository . You can also get in touch on our Slack channel. You will be invited once you [register an account] on the archive. If you want to get started right away and contribute directly to this documentation, you can find references and how-to in the about section .","title":"Contributing and feedback"},{"location":"01_introduction/","text":"Introduction Advantages of using DANDI A open data archive to submit cellular neurophysiology data. A persistent, versioned and growing collection of standardized cellular neurophysiology data. Rich metadata to support search across data. A place to house data to collaborate across research sites. Consistent and transparent data standards to simplify software development. Supported by the BRAIN Initiative and the AWS Public dataset programs. The challenges To know which data are useful, data has to be accessible. Non standardized datasets lead to significant resources to needed to undestand and adapt code to these datasets. Many different hardware platforms and custom binary formats requires significant effort to consolidate into reusable datasets. Many domain general places to house data (e.g., Open Science Framework, G-Node, Dropbox, Google drive), but difficult to find relevant datasets. Datasets are growing larger requiring compute services to be closer to data. Neurotechnology is evolving and requires flexible extensions to metadata and data storage requirements. Consolidating and creating robust algorithms (e.g., spike sorting) requires varied data sources. Our solution We have developed a FAIR -Findable.Accessible.Interoperable.Reusable data archive to house standardized cellular neurophysiology and associated data. We use the Neurodata Without Borders , Brain Imaging Data Structure , Neuroimaging Data Model and other BRAIN Initiative standards to organize and search the data. A Jupyterhub-based analysis platform provides easy access to the data. The data can be accessed programmatically allowing for new software and tools to be built. The archive itself is built on a software stack of opensource products, thus enriching the ecosystem. The archive provides persistent identifiers for versioned datasets thus improving reproducibility of neurophysiology research.","title":"Introduction"},{"location":"01_introduction/#introduction","text":"","title":"Introduction"},{"location":"01_introduction/#advantages-of-using-dandi","text":"A open data archive to submit cellular neurophysiology data. A persistent, versioned and growing collection of standardized cellular neurophysiology data. Rich metadata to support search across data. A place to house data to collaborate across research sites. Consistent and transparent data standards to simplify software development. Supported by the BRAIN Initiative and the AWS Public dataset programs.","title":"Advantages of using DANDI"},{"location":"01_introduction/#the-challenges","text":"To know which data are useful, data has to be accessible. Non standardized datasets lead to significant resources to needed to undestand and adapt code to these datasets. Many different hardware platforms and custom binary formats requires significant effort to consolidate into reusable datasets. Many domain general places to house data (e.g., Open Science Framework, G-Node, Dropbox, Google drive), but difficult to find relevant datasets. Datasets are growing larger requiring compute services to be closer to data. Neurotechnology is evolving and requires flexible extensions to metadata and data storage requirements. Consolidating and creating robust algorithms (e.g., spike sorting) requires varied data sources.","title":"The challenges"},{"location":"01_introduction/#our-solution","text":"We have developed a FAIR -Findable.Accessible.Interoperable.Reusable data archive to house standardized cellular neurophysiology and associated data. We use the Neurodata Without Borders , Brain Imaging Data Structure , Neuroimaging Data Model and other BRAIN Initiative standards to organize and search the data. A Jupyterhub-based analysis platform provides easy access to the data. The data can be accessed programmatically allowing for new software and tools to be built. The archive itself is built on a software stack of opensource products, thus enriching the ecosystem. The archive provides persistent identifiers for versioned datasets thus improving reproducibility of neurophysiology research.","title":"Our solution"},{"location":"100_about_this_doc/","text":"About this documentation This documentation is a work in progress and we wellcome any input: if something is missing or unclear, let us know by opening an issue on our repository . Serving the doc locally This project uses MkDocs tool with Material theme and extra plugins to generate the website. To test locally, you will need to install the Python dependencies. To do that, type the following commands: git clone https://github.com/dandi/handbook.git cd handbook pip install -r requirements.txt If you are working on your fork , simply replace https://github.com/dandi/handbook.git by git clone git@github.com/<username>/handbook.git where <username> is your GitHub username Once done, you need to run MkDocs. Simply type: mkdocs serve Finally, open up http://127.0.0.1:8000/ in your browser, and you should see the default home page of the being displayed.","title":"About this doc"},{"location":"100_about_this_doc/#about-this-documentation","text":"This documentation is a work in progress and we wellcome any input: if something is missing or unclear, let us know by opening an issue on our repository .","title":"About this documentation"},{"location":"100_about_this_doc/#serving-the-doc-locally","text":"This project uses MkDocs tool with Material theme and extra plugins to generate the website. To test locally, you will need to install the Python dependencies. To do that, type the following commands: git clone https://github.com/dandi/handbook.git cd handbook pip install -r requirements.txt If you are working on your fork , simply replace https://github.com/dandi/handbook.git by git clone git@github.com/<username>/handbook.git where <username> is your GitHub username Once done, you need to run MkDocs. Simply type: mkdocs serve Finally, open up http://127.0.0.1:8000/ in your browser, and you should see the default home page of the being displayed.","title":"Serving the doc locally"},{"location":"10_using_dandi/","text":"Working with DANDI DANDI provides access to and an archive to submit cellular neurophysiology datasets. We refer to such datasets as a Dandiset . A Dandiset is organized in a structured manner to help improve users and software tools can interact with it. Each Dandiset has a unique persistent identifier that you can use to go directly to the Dandiset (e.g., https://identifiers.org/DANDI:000004 ). You can use this identifier to cite the Dandiset in your publications or providing direct access to a Dandiset . DANDI components The DANDI Web application DANDI Web application allows you to: Browse Dandisets . Search across Dandisets . Create an account to register a new Dandiset or gain access to the Dandihub analysis platform . Add collaborators to your Dandiset . Retrieve an API key to perform data upload to your Dandisets . Publish versions of your Dandisets . The DANDI Python client The DANDI Python client allows you to: Download Danidsets and individual subject folders or files. Organize your data locally before upload. Upload your Dandiset The Dandihub analysis platform Dandihub provides a Jupyter environment to interact with the DANDI archive. To use the hub, you will need to register an account using the DANDI Web application . Please note that Dandihub is not intended for significant computation, but provides a place to introspect Dandisets and files. Downloading from DANDI You can download entire Dandisets or single files. Downloading a file Using the Web application. Each Dandiset has a View Data option. This provides a folder like view to navigate a Dandiset . Any file in the Dandiset has a download icon next to it. You can click this icon to download a file to your device where you are browsing or right click to get the download URL of the file. You can then use this URL programmatically or in other applications such as the NWB Explorer or in a Jupyter notebook on Dandihub . Using the Python CLI First install the Python client using pip install dandi in a Python 3.6+ environment. Downloading a Dandiset . Downloading a subject. Downloading a file. Create an account on DANDI To create an account on DANDI, you will need to. Create a Github account if you don't have one. Using your Github account register a DANDI account . Make sure to use the Register with OAuth option You will receive an email acknowledging activation of your account within 24 hours. You can now login to DANDI using the Github by clicking on the login button. Uploading a Dandiset Setup If you do not have a DANDI account, please create an account Log in to DANDI, copy your API key. This is under your user initials on the top right after logging in. Locally Create a Python environment (e.g., Miniconda, virtualenv) Install the DANDI CLI into your Python environment pip install dandi Data upload/management workflow Register a dandiset to generate an identifier. You will be asked to enter basic metadata, a name (title) and description (abstract) for your dataset. Click New Dataset in the Web application after logging in. After you are done, note the dataset identifer. We will call this <dataset_id> . Convert your data to NWB 2.1+ in a local folder. Let's call this <source_folder> This step can be complex depending on your data. Feel free to reach out to us for help . Validate the NWB files by running: dandi validate <source_folder> Preparing a dataset folder for upload: dandi download https://dandiarchive.org/<dataset_id>/draft cd <dataset_id> dandi organize <source_folder> -f dry dandi organize <source_folder> -f symlink dandi upload Add metadata on the Web. Click on the Edit metadata link by visiting your dandiset landing page: https://dandiarchive.org/<dataset_id>/draft Use the dandiset URL: in your preprint To download, anyone can use the dandi CLI: dandi download <dandiset_url> Publish a Dandiset \ud83d\udee0 Work in progress \ud83d\udee0","title":"Using DANDI"},{"location":"10_using_dandi/#working-with-dandi","text":"DANDI provides access to and an archive to submit cellular neurophysiology datasets. We refer to such datasets as a Dandiset . A Dandiset is organized in a structured manner to help improve users and software tools can interact with it. Each Dandiset has a unique persistent identifier that you can use to go directly to the Dandiset (e.g., https://identifiers.org/DANDI:000004 ). You can use this identifier to cite the Dandiset in your publications or providing direct access to a Dandiset .","title":"Working with DANDI"},{"location":"10_using_dandi/#dandi-components","text":"","title":"DANDI components"},{"location":"10_using_dandi/#the-dandi-web-application","text":"DANDI Web application allows you to: Browse Dandisets . Search across Dandisets . Create an account to register a new Dandiset or gain access to the Dandihub analysis platform . Add collaborators to your Dandiset . Retrieve an API key to perform data upload to your Dandisets . Publish versions of your Dandisets .","title":"The DANDI Web application"},{"location":"10_using_dandi/#the-dandi-python-client","text":"The DANDI Python client allows you to: Download Danidsets and individual subject folders or files. Organize your data locally before upload. Upload your Dandiset","title":"The DANDI Python client"},{"location":"10_using_dandi/#the-dandihub-analysis-platform","text":"Dandihub provides a Jupyter environment to interact with the DANDI archive. To use the hub, you will need to register an account using the DANDI Web application . Please note that Dandihub is not intended for significant computation, but provides a place to introspect Dandisets and files.","title":"The Dandihub analysis platform"},{"location":"10_using_dandi/#downloading-from-dandi","text":"You can download entire Dandisets or single files.","title":"Downloading from DANDI"},{"location":"10_using_dandi/#downloading-a-file","text":"","title":"Downloading a file"},{"location":"10_using_dandi/#using-the-web-application","text":"Each Dandiset has a View Data option. This provides a folder like view to navigate a Dandiset . Any file in the Dandiset has a download icon next to it. You can click this icon to download a file to your device where you are browsing or right click to get the download URL of the file. You can then use this URL programmatically or in other applications such as the NWB Explorer or in a Jupyter notebook on Dandihub .","title":"Using the Web application."},{"location":"10_using_dandi/#using-the-python-cli","text":"First install the Python client using pip install dandi in a Python 3.6+ environment. Downloading a Dandiset . Downloading a subject. Downloading a file.","title":"Using the Python CLI"},{"location":"10_using_dandi/#create-an-account-on-dandi","text":"To create an account on DANDI, you will need to. Create a Github account if you don't have one. Using your Github account register a DANDI account . Make sure to use the Register with OAuth option You will receive an email acknowledging activation of your account within 24 hours. You can now login to DANDI using the Github by clicking on the login button.","title":"Create an account on DANDI"},{"location":"10_using_dandi/#uploading-a-dandiset","text":"Setup If you do not have a DANDI account, please create an account Log in to DANDI, copy your API key. This is under your user initials on the top right after logging in. Locally Create a Python environment (e.g., Miniconda, virtualenv) Install the DANDI CLI into your Python environment pip install dandi Data upload/management workflow Register a dandiset to generate an identifier. You will be asked to enter basic metadata, a name (title) and description (abstract) for your dataset. Click New Dataset in the Web application after logging in. After you are done, note the dataset identifer. We will call this <dataset_id> . Convert your data to NWB 2.1+ in a local folder. Let's call this <source_folder> This step can be complex depending on your data. Feel free to reach out to us for help . Validate the NWB files by running: dandi validate <source_folder> Preparing a dataset folder for upload: dandi download https://dandiarchive.org/<dataset_id>/draft cd <dataset_id> dandi organize <source_folder> -f dry dandi organize <source_folder> -f symlink dandi upload Add metadata on the Web. Click on the Edit metadata link by visiting your dandiset landing page: https://dandiarchive.org/<dataset_id>/draft Use the dandiset URL: in your preprint To download, anyone can use the dandi CLI: dandi download <dandiset_url>","title":"Uploading a Dandiset"},{"location":"10_using_dandi/#publish-a-dandiset","text":"\ud83d\udee0 Work in progress \ud83d\udee0","title":"Publish a Dandiset"},{"location":"20_project_structure/","text":"Project structure The DANDI project is organized around several Github repositories. The main ones are the following. The DANDI archive. This repository contains the code for deploying the archive. It includes the client-side Web application frontend based on the Vuejs framework, the server backend extensions to the Girder platform , and the deployment code for pushing changes to the archive as they are merged in. The DANDI Python client. This repository contains the code for the command line tool used to interact with the archive. It allows you to download data from the archive. It also allows you to locally organize and validate your data before upload to the archive. The DANDI Jupyterhub. This repository contains the code for deploying a Jupyterhub instance to support interaction with the DANDI archive. The DANDI API. This repository provides the code for the DANDI API. The DANDI schema. This repostiory provides the details and some supporting code for the DANDI metadata schema. The DANDI handbook. This repository provides the contents of this Website. The DANDI Website. This repository provides an overview of the DANDI project and the team members and collaborators.","title":"Project structure"},{"location":"20_project_structure/#project-structure","text":"The DANDI project is organized around several Github repositories. The main ones are the following. The DANDI archive. This repository contains the code for deploying the archive. It includes the client-side Web application frontend based on the Vuejs framework, the server backend extensions to the Girder platform , and the deployment code for pushing changes to the archive as they are merged in. The DANDI Python client. This repository contains the code for the command line tool used to interact with the archive. It allows you to download data from the archive. It also allows you to locally organize and validate your data before upload to the archive. The DANDI Jupyterhub. This repository contains the code for deploying a Jupyterhub instance to support interaction with the DANDI archive. The DANDI API. This repository provides the code for the DANDI API. The DANDI schema. This repostiory provides the details and some supporting code for the DANDI metadata schema. The DANDI handbook. This repository provides the contents of this Website. The DANDI Website. This repository provides an overview of the DANDI project and the team members and collaborators.","title":"Project structure"},{"location":"30_schema/","text":"The metadata schema The core model of DANDI is based on DATS, Datacite, schema.org, and the C2M2 effort. This page describes the properties of the current objects. Common metadata Dandiset specific extesnions Asset specific extensions","title":"The metadata schema"},{"location":"30_schema/#the-metadata-schema","text":"The core model of DANDI is based on DATS, Datacite, schema.org, and the C2M2 effort. This page describes the properties of the current objects.","title":"The metadata schema"},{"location":"30_schema/#common-metadata","text":"","title":"Common metadata"},{"location":"30_schema/#dandiset-specific-extesnions","text":"","title":"Dandiset specific extesnions"},{"location":"30_schema/#asset-specific-extensions","text":"","title":"Asset specific extensions"},{"location":"98_FAQ/","text":"FAQ Who is DANDI for? DANDI can be useful to any individuals interested in neuroscience and/or large and diverse datascience challenges.","title":"FAQ"},{"location":"98_FAQ/#faq","text":"","title":"FAQ"},{"location":"98_FAQ/#who-is-dandi-for","text":"DANDI can be useful to any individuals interested in neuroscience and/or large and diverse datascience challenges.","title":"Who is DANDI for?"},{"location":"99_glossary/","text":"Glossary Asset BIDS Dandiset NIDM NWB","title":"Glossary"},{"location":"99_glossary/#glossary","text":"Asset BIDS Dandiset NIDM NWB","title":"Glossary"}]}